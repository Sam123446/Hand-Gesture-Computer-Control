Hand Gesture-Based Human–Computer Interaction System
This project uses computer vision and AI to enable full computer control using hand gestures. Using a webcam and MediaPipe hand tracking, the system detects your hand and fingers in real-time, interprets gestures, and maps them to mouse and keyboard actions.

It allows you to:

*Move the mouse cursor by pointing your index finger.
*Perform single click, double click, drag-and-drop, and screenshot gestures.
*Control your computer without a physical mouse or keyboard.
  *Add new gestures to extend functionality.

The system is real-time, optimized for smooth movement, and demonstrates practical Human–Computer Interaction (HCI) using computer vision.
Technologies Used:
Python 3.10+
OpenCV for video capture and image processing
MediaPipe for hand landmark detection
PyAutoGUI for mapping gestures to computer control
NumPy for math operations
